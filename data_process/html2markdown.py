#!/usr/bin/env python3
"""
æ‰¹é‡å°†HTMLå†…å®¹è½¬æ¢ä¸ºMarkdownæ ¼å¼
ä»domain_samplesç›®å½•è¯»å–JSONæ–‡ä»¶ï¼Œå¤„ç†å…¶ä¸­çš„HTMLå†…å®¹å¹¶ä¿å­˜æ–°æ–‡ä»¶
"""

import sys
import os
import json
import glob
import argparse
from pathlib import Path
from tqdm import tqdm
import multiprocessing as mp
from functools import partial

# æ·»åŠ code-html-to-markdownç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), 'code-html-to-markdown'))

# å¯¼å…¥å‡½æ•°
from main import code_html_to_markdown

def process_single_file(file_args):
    """
    å¤„ç†å•ä¸ªJSONæ–‡ä»¶ï¼ˆå¤šè¿›ç¨‹ç‰ˆæœ¬ï¼‰
    """
    json_file, output_suffix, verbose = file_args
    return _process_single_file(json_file, output_suffix, verbose)

def _process_single_file(json_file, output_suffix="_markdown", verbose=True):
    """
    å¤„ç†å•ä¸ªJSONæ–‡ä»¶ï¼Œå°†contentå­—æ®µçš„HTMLè½¬æ¢ä¸ºMarkdown
    """
    try:
        # è¯»å–JSONæ–‡ä»¶
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if not isinstance(data, list):
            if verbose:
                print(f"  è­¦å‘Š: {os.path.basename(json_file)} ä¸æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œè·³è¿‡")
            return None
        
        processed_count = 0
        error_count = 0
        
        # å¤„ç†æ¯æ¡æ•°æ®
        for item in data:
            if isinstance(item, dict) and 'content' in item:
                try:
                    html_content = item['content']
                    if html_content and isinstance(html_content, str):
                        # è½¬æ¢HTMLä¸ºMarkdown
                        markdown_content = code_html_to_markdown(html_content)
                        item['content'] = markdown_content
                        item['content_format'] = 'markdown'  # æ·»åŠ æ ¼å¼æ ‡è®°
                        processed_count += 1
                    else:
                        # ç©ºå†…å®¹æˆ–éå­—ç¬¦ä¸²å†…å®¹ï¼Œæ ‡è®°ä¸ºåŸå§‹æ ¼å¼
                        item['content_format'] = 'raw'
                except Exception as e:
                    if verbose:
                        print(f"    è½¬æ¢é”™è¯¯: {str(e)[:100]}...")
                    error_count += 1
                    # ä¿ç•™åŸå§‹å†…å®¹ï¼Œæ ‡è®°ä¸ºé”™è¯¯
                    item['content_format'] = 'error'
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        file_path = Path(json_file)
        output_file = file_path.parent / f"{file_path.stem}{output_suffix}.json"
        
        # ä¿å­˜å¤„ç†åçš„æ•°æ®
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        return {
            'input_file': json_file,
            'output_file': str(output_file),
            'total_items': len(data),
            'processed_items': processed_count,
            'error_items': error_count,
            'success': True
        }
        
    except Exception as e:
        return {
            'input_file': json_file,
            'output_file': None,
            'total_items': 0,
            'processed_items': 0,
            'error_items': 0,
            'success': False,
            'error': str(e)
        }

def find_json_files(input_dir, exclude_suffix="_markdown"):
    """
    æŸ¥æ‰¾è¾“å…¥ç›®å½•ä¸‹æ‰€æœ‰çš„JSONæ–‡ä»¶ï¼ˆæ’é™¤è¾“å‡ºæ–‡ä»¶ï¼‰
    """
    json_files = []
    
    # éå†æ‰€æœ‰å­ç›®å½•
    for domain_dir in os.listdir(input_dir):
        domain_path = os.path.join(input_dir, domain_dir)
        if os.path.isdir(domain_path):
            # æŸ¥æ‰¾è¯¥åŸŸåç›®å½•ä¸‹çš„JSONæ–‡ä»¶
            pattern = os.path.join(domain_path, "*.json")
            files = glob.glob(pattern)
            
            # è¿‡æ»¤æ‰ä»¥exclude_suffixç»“å°¾çš„æ–‡ä»¶
            filtered_files = [
                f for f in files 
                if not os.path.basename(f).endswith(f"{exclude_suffix}.json")
            ]
            json_files.extend(filtered_files)
    
    return json_files

def cleanup_existing_output_files(input_dir, output_suffix):
    """
    æ¸…ç†ç›®å½•ä¸‹æ‰€æœ‰ä»¥æŒ‡å®šåç¼€ç»“å°¾çš„æ–‡ä»¶
    """
    deleted_count = 0
    
    # éå†æ‰€æœ‰å­ç›®å½•
    for domain_dir in os.listdir(input_dir):
        domain_path = os.path.join(input_dir, domain_dir)
        if os.path.isdir(domain_path):
            # æŸ¥æ‰¾ä»¥output_suffixç»“å°¾çš„JSONæ–‡ä»¶
            pattern = os.path.join(domain_path, f"*{output_suffix}.json")
            files_to_delete = glob.glob(pattern)
            
            for file_path in files_to_delete:
                try:
                    os.remove(file_path)
                    deleted_count += 1
                except Exception as e:
                    print(f"  è­¦å‘Š: æ— æ³•åˆ é™¤æ–‡ä»¶ {file_path}: {e}")
    
    return deleted_count

def group_files_by_directory(json_files):
    """
    å°†æ–‡ä»¶æŒ‰æ‰€åœ¨ç›®å½•åˆ†ç»„
    """
    grouped_files = {}
    
    for file_path in json_files:
        directory = os.path.dirname(file_path)
        if directory not in grouped_files:
            grouped_files[directory] = []
        grouped_files[directory].append(file_path)
    
    return grouped_files

def process_directory_files(dir_args):
    """
    å¤„ç†å•ä¸ªç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶å¹¶åˆå¹¶ï¼ˆå¤šè¿›ç¨‹ç‰ˆæœ¬ï¼‰
    """
    directory_path, files_in_dir, output_suffix, verbose = dir_args
    return _process_directory_files(directory_path, files_in_dir, output_suffix, verbose)

def _process_directory_files(directory_path, files_in_dir, output_suffix="_markdown", verbose=True):
    """
    å¤„ç†å•ä¸ªç›®å½•ä¸‹çš„æ‰€æœ‰JSONæ–‡ä»¶å¹¶åˆå¹¶ä¸ºä¸€ä¸ªæ–‡ä»¶
    """
    try:
        all_processed_data = []
        total_items = 0
        processed_count = 0
        error_count = 0
        
        directory_name = os.path.basename(directory_path)
        
        if verbose:
            print(f"  å¤„ç†ç›®å½•: {directory_name} ({len(files_in_dir)} ä¸ªæ–‡ä»¶)")
        
        # å¤„ç†ç›®å½•ä¸‹çš„æ¯ä¸ªJSONæ–‡ä»¶
        for json_file in files_in_dir:
            try:
                # è¯»å–JSONæ–‡ä»¶
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                if not isinstance(data, list):
                    if verbose:
                        print(f"    è­¦å‘Š: {os.path.basename(json_file)} ä¸æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œè·³è¿‡")
                    continue
                
                # å¤„ç†æ¯æ¡æ•°æ®
                for item in data:
                    total_items += 1
                    if isinstance(item, dict) and 'content' in item:
                        try:
                            html_content = item['content']
                            if html_content and isinstance(html_content, str):
                                # è½¬æ¢HTMLä¸ºMarkdown
                                markdown_content = code_html_to_markdown(html_content)
                                item['content'] = markdown_content
                                item['content_format'] = 'markdown'
                                item['source_file'] = os.path.basename(json_file)  # è®°å½•æºæ–‡ä»¶
                                processed_count += 1
                            else:
                                item['content_format'] = 'raw'
                                item['source_file'] = os.path.basename(json_file)
                        except Exception as e:
                            if verbose:
                                print(f"      è½¬æ¢é”™è¯¯: {str(e)[:100]}...")
                            error_count += 1
                            item['content_format'] = 'error'
                            item['source_file'] = os.path.basename(json_file)
                    
                    all_processed_data.append(item)
                        
            except Exception as e:
                if verbose:
                    print(f"    æ–‡ä»¶è¯»å–é”™è¯¯ {json_file}: {e}")
                continue
        
        if not all_processed_data:
            return {
                'directory': directory_path,
                'output_file': None,
                'total_items': 0,
                'processed_items': 0,
                'error_items': 0,
                'success': False,
                'error': 'æ²¡æœ‰æœ‰æ•ˆæ•°æ®'
            }
        
        # ç”Ÿæˆåˆå¹¶åçš„è¾“å‡ºæ–‡ä»¶å
        output_file = os.path.join(directory_path, f"{directory_name}{output_suffix}.json")
        
        # ä¿å­˜åˆå¹¶åçš„æ•°æ®
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(all_processed_data, f, ensure_ascii=False, indent=2)
        
        if verbose:
            print(f"    âœ“ åˆå¹¶å®Œæˆ: {len(all_processed_data)} æ¡æ•°æ® -> {os.path.basename(output_file)}")
        
        return {
            'directory': directory_path,
            'output_file': output_file,
            'source_files': len(files_in_dir),
            'total_items': total_items,
            'processed_items': processed_count,
            'error_items': error_count,
            'success': True
        }
        
    except Exception as e:
        return {
            'directory': directory_path,
            'output_file': None,
            'source_files': len(files_in_dir),
            'total_items': 0,
            'processed_items': 0,
            'error_items': 0,
            'success': False,
            'error': str(e)
        }

def main():
    parser = argparse.ArgumentParser(description='æ‰¹é‡å°†HTMLå†…å®¹è½¬æ¢ä¸ºMarkdownæ ¼å¼')
    parser.add_argument('--input-dir', 
                       default='/mnt/hdfs/tiktok_aiic_new/user/tianyu/opencoder/dataset/domain_samples',
                       help='è¾“å…¥ç›®å½•è·¯å¾„ï¼ˆåŒ…å«å„ä¸ªåŸŸåæ–‡ä»¶å¤¹ï¼‰')
    parser.add_argument('--output-suffix', default='_markdown',
                       help='è¾“å‡ºæ–‡ä»¶åç¼€ï¼ˆé»˜è®¤_markdownï¼‰')
    parser.add_argument('--workers', type=int, default=None,
                       help='å¹¶è¡Œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤è‡ªåŠ¨ï¼‰')
    parser.add_argument('--single-process', action='store_true',
                       help='å¼ºåˆ¶ä½¿ç”¨å•è¿›ç¨‹æ¨¡å¼')
    parser.add_argument('--test', action='store_true',
                       help='æµ‹è¯•æ¨¡å¼ï¼Œåªå¤„ç†å‰5ä¸ªæ–‡ä»¶')
    parser.add_argument('--verbose', action='store_true',
                       help='æ˜¾ç¤ºè¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    print("=== HTMLè½¬Markdownæ‰¹å¤„ç†å·¥å…· ===")
    print(f"è¾“å…¥ç›®å½•: {args.input_dir}")
    print(f"è¾“å‡ºåç¼€: {args.output_suffix}")
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import trafilatura
        print("âœ“ trafilatura ä¾èµ–æ£€æŸ¥é€šè¿‡")
    except ImportError:
        print("âœ— ç¼ºå°‘ trafilatura ä¾èµ–ï¼Œè¯·å®‰è£…: pip install trafilatura")
        return
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(args.input_dir):
        print(f"âœ— è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {args.input_dir}")
        return
    
    # æ¸…ç†å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶
    print(f"\næ¸…ç†å·²å­˜åœ¨çš„{args.output_suffix}æ–‡ä»¶...")
    deleted_count = cleanup_existing_output_files(args.input_dir, args.output_suffix)
    if deleted_count > 0:
        print(f"âœ“ å·²åˆ é™¤ {deleted_count} ä¸ªæ—§çš„è¾“å‡ºæ–‡ä»¶")
    else:
        print("âœ“ æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ¸…ç†çš„æ–‡ä»¶")
    
    # æŸ¥æ‰¾æ‰€æœ‰JSONæ–‡ä»¶ï¼ˆæ’é™¤è¾“å‡ºæ–‡ä»¶ï¼‰
    print("\næŸ¥æ‰¾JSONæ–‡ä»¶...")
    json_files = find_json_files(args.input_dir, args.output_suffix)
    
    if not json_files:
        print("âœ— æ²¡æœ‰æ‰¾åˆ°ä»»ä½•JSONæ–‡ä»¶")
        return
    
    # æŒ‰ç›®å½•åˆ†ç»„æ–‡ä»¶
    grouped_files = group_files_by_directory(json_files)
    
    if args.test:
        # æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰å‡ ä¸ªç›®å½•
        test_dirs = list(grouped_files.keys())[:3]
        grouped_files = {k: v for k, v in grouped_files.items() if k in test_dirs}
        print(f"æµ‹è¯•æ¨¡å¼ï¼šå¤„ç† {len(grouped_files)} ä¸ªç›®å½•")
    else:
        print(f"æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶ï¼Œåˆ†å¸ƒåœ¨ {len(grouped_files)} ä¸ªç›®å½•ä¸­")
    
    # æ˜¾ç¤ºåˆ†ç»„ä¿¡æ¯
    if args.verbose:
        print("\nç›®å½•åˆ†ç»„ä¿¡æ¯:")
        for directory, files in grouped_files.items():
            dir_name = os.path.basename(directory)
            print(f"  {dir_name}: {len(files)} ä¸ªæ–‡ä»¶")
    
    # è®¾ç½®å¹¶è¡Œå‚æ•°
    max_workers = args.workers or min(mp.cpu_count(), len(grouped_files), 8)
    use_multiprocessing = not args.single_process and len(grouped_files) > 1
    
    if use_multiprocessing:
        print(f"\nä½¿ç”¨ {max_workers} ä¸ªè¿›ç¨‹å¹¶è¡Œå¤„ç† {len(grouped_files)} ä¸ªç›®å½•")
    else:
        print(f"\nä½¿ç”¨å•è¿›ç¨‹æ¨¡å¼å¤„ç† {len(grouped_files)} ä¸ªç›®å½•")
    
    # å¤„ç†æ–‡ä»¶ï¼ˆæŒ‰ç›®å½•åˆå¹¶ï¼‰
    results = []
    
    if use_multiprocessing:
        # å¤šè¿›ç¨‹æ¨¡å¼
        args_list = [
            (directory_path, files_in_dir, args.output_suffix, args.verbose)
            for directory_path, files_in_dir in grouped_files.items()
        ]
        
        with mp.Pool(max_workers) as pool:
            all_results = list(tqdm(
                pool.imap(process_directory_files, args_list),
                total=len(args_list),
                desc="å¤šè¿›ç¨‹å¤„ç†ç›®å½•"
            ))
        
        results = all_results
    else:
        # å•è¿›ç¨‹æ¨¡å¼
        for directory_path, files_in_dir in tqdm(grouped_files.items(), desc="å¤„ç†ç›®å½•"):
            result = _process_directory_files(directory_path, files_in_dir, args.output_suffix, args.verbose)
            results.append(result)
    
    # ç»Ÿè®¡ç»“æœ
    successful = [r for r in results if r and r['success']]
    failed = [r for r in results if r and not r['success']]
    
    total_dirs = len(grouped_files)
    total_source_files = sum(r['source_files'] for r in successful)
    total_items = sum(r['total_items'] for r in successful)
    total_processed = sum(r['processed_items'] for r in successful)
    total_errors = sum(r['error_items'] for r in successful)
    
    print(f"\n=== å¤„ç†æ‘˜è¦ ===")
    print(f"å¤„ç†ç›®å½•æ•°: {total_dirs}")
    print(f"æºæ–‡ä»¶æ€»æ•°: {total_source_files}")
    print(f"æˆåŠŸå¤„ç†ç›®å½•: {len(successful)}")
    print(f"å¤„ç†å¤±è´¥ç›®å½•: {len(failed)}")
    print(f"æ•°æ®é¡¹æ€»æ•°: {total_items}")
    print(f"æˆåŠŸè½¬æ¢: {total_processed}")
    print(f"è½¬æ¢é”™è¯¯: {total_errors}")
    print(f"è½¬æ¢ç‡: {(total_processed/total_items*100):.2f}%" if total_items > 0 else "0%")
    print(f"ç”Ÿæˆåˆå¹¶æ–‡ä»¶: {len(successful)} ä¸ª")
    
    # æ˜¾ç¤ºå¤±è´¥çš„ç›®å½•
    if failed:
        print(f"\nå¤„ç†å¤±è´¥çš„ç›®å½•:")
        for result in failed:
            dir_name = os.path.basename(result['directory'])
            print(f"  âœ— {dir_name}: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    # æ˜¾ç¤ºæˆåŠŸçš„ç›®å½•ç¤ºä¾‹
    if successful and args.verbose:
        print(f"\næˆåŠŸå¤„ç†çš„ç›®å½•ç¤ºä¾‹:")
        for result in successful[:5]:
            dir_name = os.path.basename(result['directory'])
            output_name = os.path.basename(result['output_file'])
            print(f"  âœ“ {dir_name}: {result['source_files']} æ–‡ä»¶ -> {output_name} "
                  f"({result['processed_items']}/{result['total_items']} é¡¹)")
    
    # æ˜¾ç¤ºæ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶
    if successful:
        print(f"\nç”Ÿæˆçš„åˆå¹¶æ–‡ä»¶:")
        for result in successful:
            output_name = os.path.basename(result['output_file'])
            print(f"  ğŸ“„ {output_name}")
    
    print("\nå¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    main()