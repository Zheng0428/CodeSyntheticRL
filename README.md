# CodeSyntheticRL

ä¸€ä¸ªç”¨äºä»£ç åˆæˆå¼ºåŒ–å­¦ä¹ çš„æ¨¡å—åŒ–æ¡†æ¶ï¼Œæ”¯æŒä»£ç ç”Ÿæˆä»»åŠ¡å’Œè´¨é‡è¯„ä¼°çš„ç«¯åˆ°ç«¯æµç¨‹ã€‚

## ğŸš€ é¡¹ç›®æ¦‚è¿°

CodeSyntheticRL æ˜¯ä¸€ä¸ªåä½œå¼€å‘çš„æ¡†æ¶ï¼Œæä¾›äº†æ ‡å‡†åŒ–çš„æ¥å£æ¥ï¼š

- **ç”Ÿæˆä»£ç ç›¸å…³çš„è®­ç»ƒæ•°æ®**ï¼šé€šè¿‡ LLM ç”Ÿæˆå„ç§ä»£ç ä»»åŠ¡çš„é—®ç­”å¯¹
- **è¯„ä¼°ä»£ç è´¨é‡**ï¼šæä¾›å¤šç§è¯„åˆ†æœºåˆ¶ï¼ŒåŒ…æ‹¬è§„åˆ™æ£€æŸ¥å’Œ LLM åˆ¤æ–­
- **æ”¯æŒå¼ºåŒ–å­¦ä¹ è®­ç»ƒ**ï¼šä¸ºä»£ç ç”Ÿæˆæ¨¡å‹æä¾›å¥–åŠ±ä¿¡å·

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„

### ä¸»è¦ç»„ä»¶

```
CodeSyntheticRL/
â”œâ”€â”€ ğŸ“ generation/           # ä»£ç ç”Ÿæˆä»»åŠ¡æ¨¡å—
â”‚   â”œâ”€â”€ algo_complexity_pred/ # ç¤ºä¾‹ï¼šç®—æ³•å¤æ‚åº¦é¢„æµ‹ä»»åŠ¡
â”‚   â””â”€â”€ [your_task]/         # ä½ çš„æ–°ä»»åŠ¡
â”œâ”€â”€ ğŸ“ reward_score/         # å¥–åŠ±è¯„åˆ†æ¨¡å—
â”‚   â”œâ”€â”€ algo_complexity_pred.py # ç¤ºä¾‹è¯„åˆ†å™¨
â”‚   â””â”€â”€ [your_scorer].py    # ä½ çš„æ–°è¯„åˆ†å™¨
â”œâ”€â”€ ğŸ“ prompt/               # LLM æç¤ºæ¨¡æ¿
â”œâ”€â”€ ğŸ“ config/               # ä»»åŠ¡é…ç½®æ–‡ä»¶
â”œâ”€â”€ ğŸ“ sandbox/              # ä»£ç æ‰§è¡Œæ²™ç®±
â”œâ”€â”€ ğŸ“ data_process/         # æ•°æ®å¤„ç†å·¥å…·ï¼ˆè¯¦è§å­ç›®å½• READMEï¼‰
â”œâ”€â”€ ğŸ“„ utils.py              # æ ¸å¿ƒå·¥å…·å’Œæ³¨å†Œç³»ç»Ÿ
â”œâ”€â”€ ğŸ“„ generation.py         # ä¸»å…¥å£ç¨‹åº
â””â”€â”€ ğŸ“„ envs.py               # ç¯å¢ƒé…ç½®
```

### æ ¸å¿ƒè®¾è®¡ç†å¿µ

- **æ’ä»¶åŒ–æ¶æ„**ï¼šä½¿ç”¨è£…é¥°å™¨æ³¨å†Œç³»ç»Ÿï¼Œæ–°ä»»åŠ¡å³æ’å³ç”¨
- **æ ‡å‡†åŒ–æ¥å£**ï¼šç»Ÿä¸€çš„è¾“å…¥è¾“å‡ºæ ¼å¼å’Œå‡½æ•°ç­¾å
- **é…ç½®é©±åŠ¨**ï¼šé€šè¿‡ YAML é…ç½®æ–‡ä»¶æ§åˆ¶ä»»åŠ¡æ‰§è¡Œ
- **æ··åˆè¯„åˆ†**ï¼šæ”¯æŒè§„åˆ™åŒ¹é… + LLM åˆ¤æ–­çš„åŒé‡è¯„ä¼°

## ğŸ”§ æ ¸å¿ƒæœºåˆ¶

### è£…é¥°å™¨æ³¨å†Œç³»ç»Ÿ

æ¡†æ¶ä½¿ç”¨ä¸¤ä¸ªæ ¸å¿ƒè£…é¥°å™¨æ¥å®ç°ä»»åŠ¡æ³¨å†Œï¼š

```python
from utils import register_forward, register_reward_score

# æ³¨å†Œæ•°æ®ç”Ÿæˆä»»åŠ¡
@register_forward("task_name")
def forward(args):
    # ç”Ÿæˆé€»è¾‘
    pass

# æ³¨å†Œè¯„åˆ†å‡½æ•°
@register_reward_score("scorer_name") 
def compute_score(solution_str, ground_truth, extra_info):
    # è¯„åˆ†é€»è¾‘
    return {"score": score, "extra_info": info}
```

### LLM é›†æˆ

æ¡†æ¶æä¾›äº†ä¾¿æ·çš„ LLM è°ƒç”¨æ¥å£ï¼š

```python
from utils import get_llm_response, get_llm_responses_batch

# å•ä¸ªè¯·æ±‚
response = get_llm_response(prompt, temperature=0.7)

# æ‰¹é‡å¹¶å‘è¯·æ±‚ï¼ˆæ¨èï¼‰
responses = get_llm_responses_batch(
    prompts=prompts,
    batch_size=100,
    max_concurrency=15
)
```

## ğŸ“Š æ•°æ®èµ„æº

æœ¬é¡¹ç›®çš„å¯ç”¨æ•°æ®é›†å·²å‘å¸ƒåœ¨ Hugging Face Collectionsï¼š

ğŸ”— **æ•°æ®é›†é“¾æ¥**: [Code Synthetic RL Rollout Collection](https://huggingface.co/collections/aaabiao/code-synthetic-rl-rollout-68b9220c78768a27941a3f2c)

è¯¥ Collection åŒ…å«äº†å„ç§ä»£ç ä»»åŠ¡çš„åŸºç¡€æ•°æ®ï¼Œä½ å¯ä»¥ï¼š
- æµè§ˆå·²æœ‰çš„æ•°æ®é›†æ ¼å¼ä½œä¸ºå‚è€ƒ
- æœ‰æ–°éœ€æ±‚å¯ä»¥ç›´æ¥ @éƒ‘å¤©æ˜±

## ğŸ“‹ ä»»åŠ¡æ–‡æ¡£

è¯¦ç»†çš„ä»»åŠ¡éœ€æ±‚å’Œå¼€å‘æŒ‡å—è¯·æŸ¥çœ‹ï¼š

ğŸ”— **ä»»åŠ¡æ–‡æ¡£**: [Code Synthetic RL](https://bytedance.larkoffice.com/docx/C14PdjpiCoA4MPxNjcCcaKGYnqb)


## ğŸ“ å¿«é€Ÿå¼€å§‹ - åŸºäºç¤ºä¾‹å­¦ä¹ 

### 1. ç¯å¢ƒé…ç½®

```bash
# å®‰è£…ä¾èµ–
pip install requests yaml tqdm aiohttp

# é…ç½® LLM API
cp envs.py.example envs.py
# ç¼–è¾‘ envs.py è®¾ç½®ä½ çš„ API_KEY å’Œ BASE_URL
```

### 2. è¿è¡Œç¤ºä¾‹ä»»åŠ¡

```bash
# è¿è¡Œç®—æ³•å¤æ‚åº¦é¢„æµ‹ä»»åŠ¡
python generation.py --config_name algo_complexity_pred

# æµ‹è¯•è¯„åˆ†å™¨
python reward_score/algo_complexity_pred.py
```

## ğŸ› ï¸ å¦‚ä½•æ·»åŠ æ–°ä»»åŠ¡

### Step 1: åˆ›å»ºç”Ÿæˆä»»åŠ¡

ä»¥ `algo_complexity_pred` ä¸ºæ¨¡æ¿ï¼š

**1. åˆ›å»ºä»»åŠ¡ç›®å½•ç»“æ„**
```bash
mkdir generation/[your_task_name]
touch generation/[your_task_name]/__init__.py
touch generation/[your_task_name]/main.py
```

**2. å®ç°ç”Ÿæˆå‡½æ•°** (`generation/[your_task_name]/main.py`)
```python
from utils import register_forward, get_llm_responses_batch, read_yaml

@register_forward("[your_task_name]")
def forward(args):
    """
    å‚è€ƒ algo_complexity_pred/main.py çš„å®ç°æ¨¡å¼
    """
    input_path = args['input_path']
    output_path = args['output_path']
    
    # 1. åŠ è½½æ•°æ®
    data = load_your_data(input_path)
    
    # 2. è¯»å– prompt æ¨¡æ¿
    template = read_yaml('[your_task_name]')
    
    # 3. å‡†å¤‡ LLM prompts
    prompts = []
    for item in data:
        prompt = template['prompt_template'].format(**item)
        prompts.append(prompt)
    
    # 4. æ‰¹é‡è°ƒç”¨ LLM
    responses = get_llm_responses_batch(prompts)
    
    # 5. è§£æå¹¶ä¿å­˜ç»“æœ
    results = []
    for response in responses:
        parsed = parse_your_response(response)  # è‡ªå®šä¹‰è§£æé€»è¾‘
        results.append(parsed)
    
    save_results(results, output_path)
```

**3. åˆ›å»º prompt æ¨¡æ¿** (`prompt/[your_task_name].yaml`)
```yaml
prompt_template: |
  Your task description here...
  
  Input: {input_field}
  
  Generate: specific requirements
  
  Output format:
  [define your expected format]
```

**4. åˆ›å»ºé…ç½®æ–‡ä»¶** (`config/[your_task_name].yaml`)
```yaml
forward: [your_task_name]
input_path: /path/to/your/input/data
output_path: /path/to/your/output/data
limit: 0  # 0 for no limit
llm: true
# å…¶ä»–è‡ªå®šä¹‰å‚æ•°
```

### Step 2: åˆ›å»ºè¯„åˆ†å™¨

å‚è€ƒ `reward_score/algo_complexity_pred.py`ï¼š

**1. åˆ›å»ºè¯„åˆ†å™¨æ–‡ä»¶** (`reward_score/[your_task_name].py`)
```python
from utils import register_reward_score

@register_reward_score("[your_task_name]")
def compute_score(solution_str, ground_truth, extra_info):
    """
    å‚è€ƒ algo_complexity_pred.py çš„æ··åˆè¯„åˆ†ç­–ç•¥ï¼š
    1. å…ˆå°è¯•è§„åˆ™åŒ¹é…
    2. å¤±è´¥æ—¶ä½¿ç”¨ LLM åˆ¤æ–­
    """
    
    # è§„åˆ™åŒ¹é…é€»è¾‘
    rule_based_result = your_rule_based_check(solution_str, ground_truth)
    
    if rule_based_result is not None:
        return {
            "score": 1.0 if rule_based_result else 0.0,
            "extra_info": {
                "method": "rule_based",
                "extracted": rule_based_result
            }
        }
    
    # LLM åˆ¤æ–­é€»è¾‘
    llm_result = your_llm_judgment(solution_str, ground_truth)
    
    return {
        "score": 1.0 if llm_result else 0.0,
        "extra_info": {
            "method": "llm_judgment",
            "details": "..."
        }
    }

def test_[your_task_name]():
    """æ·»åŠ æµ‹è¯•ç”¨ä¾‹"""
    test_cases = [
        ("input1", "expected1", 1.0),
        ("input2", "expected2", 0.0),
    ]
    
    for solution, ground_truth, expected in test_cases:
        result = compute_score(solution, ground_truth, None)
        assert abs(result["score"] - expected) < 1e-6

if __name__ == "__main__":
    test_[your_task_name]()
    print("All tests passed!")
```

### Step 3: è¿è¡Œä½ çš„ä»»åŠ¡

```bash
# è¿è¡Œæ•°æ®ç”Ÿæˆ
python generation.py --config_name [your_task_name]

# æµ‹è¯•è¯„åˆ†å™¨
python reward_score/[your_task_name].py
```

## ğŸ“‹ å¼€å‘è§„èŒƒ

### å¿…é¡»éµå¾ªçš„æ¥å£

**Generation ä»»åŠ¡ï¼š**
- å‡½æ•°åå¿…é¡»æ˜¯ `forward`
- å¿…é¡»æ¥å— `args` å‚æ•°ï¼ˆå­—å…¸æ ¼å¼ï¼‰
- å¿…é¡»åŒ…å« `input_path` å’Œ `output_path`
- ä½¿ç”¨ `@register_forward("task_name")` è£…é¥°å™¨

**Reward Score è¯„åˆ†å™¨ï¼š**
- å‡½æ•°åå¿…é¡»æ˜¯ `compute_score`
- å‚æ•°ï¼š`(solution_str, ground_truth, extra_info)`
- è¿”å›ï¼š`{"score": float, "extra_info": dict}`
- ä½¿ç”¨ `@register_reward_score("scorer_name")` è£…é¥°å™¨

### æ¨èå®è·µ

1. **æ··åˆè¯„åˆ†ç­–ç•¥**ï¼šä¼˜å…ˆä½¿ç”¨è§„åˆ™åŒ¹é…ï¼Œå¤±è´¥æ—¶è°ƒç”¨ LLM
2. **æ‰¹é‡å¤„ç†**ï¼šä½¿ç”¨ `get_llm_responses_batch` æé«˜æ•ˆç‡
3. **é”™è¯¯å¤„ç†**ï¼šæ·»åŠ  try-catch å’Œé‡è¯•æœºåˆ¶
4. **æµ‹è¯•ç”¨ä¾‹**ï¼šä¸ºæ¯ä¸ªè¯„åˆ†å™¨æ·»åŠ æµ‹è¯•å‡½æ•°
5. **æ–‡æ¡£è¯´æ˜**ï¼šåœ¨ä»£ç ä¸­æ·»åŠ æ¸…æ™°çš„æ³¨é‡Š

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

æ¯ä¸ªæ–°ä»»åŠ¡éƒ½åº”è¯¥åŒ…å«æµ‹è¯•ï¼š

```python
# åœ¨è¯„åˆ†å™¨æ–‡ä»¶ä¸­æ·»åŠ æµ‹è¯•
def test_your_scorer():
    # æ­£ç¡®æ¡ˆä¾‹
    result = compute_score("correct_answer", "ground_truth", None)
    assert result["score"] == 1.0
    
    # é”™è¯¯æ¡ˆä¾‹
    result = compute_score("wrong_answer", "ground_truth", None)
    assert result["score"] == 0.0

if __name__ == "__main__":
    test_your_scorer()
```

## ğŸ“Š é¡¹ç›®çŠ¶æ€

### å·²å®Œæˆçš„ä»»åŠ¡ç¤ºä¾‹
- âœ… **algo_complexity_pred**: ç®—æ³•å¤æ‚åº¦é¢„æµ‹ - å®Œæ•´å®ç°åŒ…æ‹¬æ··åˆè¯„åˆ†ç­–ç•¥

### ç­‰å¾…å¼€å‘çš„ä»»åŠ¡
- ğŸ”„ **ä½ çš„ä»»åŠ¡**: è¯·åŸºäº algo_complexity_pred çš„æ¨¡å¼æ¥å®ç°

## ğŸ¤ åä½œæŒ‡å—

1. **Fork é¡¹ç›®**ï¼šåˆ›å»ºä½ çš„åˆ†æ”¯è¿›è¡Œå¼€å‘
2. **éµå¾ªç¤ºä¾‹**ï¼šä¸¥æ ¼æŒ‰ç…§ `algo_complexity_pred` çš„æ¨¡å¼å®ç°
3. **æµ‹è¯•å……åˆ†**ï¼šç¡®ä¿ä½ çš„è¯„åˆ†å™¨é€šè¿‡æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹
4. **æ–‡æ¡£æ¸…æ™°**ï¼šä¸ºä½ çš„ä»»åŠ¡æ·»åŠ æ¸…æ™°çš„è¯´æ˜
5. **æäº¤ PR**ï¼šå®Œæˆåæäº¤ Pull Request

## âš ï¸ é‡è¦æé†’

- æ–°ä»»åŠ¡çš„å‘½åå¿…é¡»å”¯ä¸€ï¼Œé¿å…å†²çª
- ä¸¥æ ¼éµå¾ª `forward` å’Œ `compute_score` çš„å‡½æ•°ç­¾å
- LLM è°ƒç”¨éœ€è¦é…ç½®æ­£ç¡®çš„ API å¯†é’¥
- å¤§è§„æ¨¡æ•°æ®å¤„ç†æ—¶æ³¨æ„å†…å­˜å’ŒAPIé™åˆ¶
- å®šæœŸè¿è¡Œæµ‹è¯•ç¡®ä¿åŠŸèƒ½æ­£å¸¸

## ğŸ“š æ›´å¤šä¿¡æ¯

- **æ•°æ®å¤„ç†å·¥å…·**ï¼šè¯¦è§ `./data_process/README.md`
- **æ²™ç®±ä½¿ç”¨**ï¼šè¯¦è§ `./sandbox/README.md`
- **ç¤ºä¾‹ä»£ç **ï¼šå‚è€ƒ `generation/algo_complexity_pred/` å’Œ `reward_score/algo_complexity_pred.py`

---

**å¼€å§‹å¼€å‘ä½ çš„ç¬¬ä¸€ä¸ªä»»åŠ¡å§ï¼** ğŸš€